---
title: "Practical Machine Learning 2014"
author: "Costas Voglis"
date: "Friday, December 05, 2014"
output: html_document
---
#Programming Assignement - Weight Lifting Exercise Dataset

In this assignement the task was to predict a weight lifting exercise class using
data from accelerometers, attached on the body of 6 individuals. Each class
represents a different type of exercise. We will divide the process in two phases

1. Data preprocessing: Perform analysis on the columns of the original data and keep only the meaningful ones
2. Model selection: Perform parameter analysis on various well known classifiers

## 1.Data preprocessing
Initialy we load the data using: 
```{r, echo=TRUE}
library(caret)
dataOriginal<-read.csv("pml-training.csv")
````

A quick look in the dimensionality of the data frame reveals that we have 19622 observations
with 160 columns.
```{r, echo=TRUE}
dim(dataOriginal)
```

We can discard the first 5 columns since they represent user data and timestamps
```{r, echo=TRUE}
head(dataOriginal[, (1:5)])
dataOriginal<-dataOriginal[, -(1:5)]
```

Find near zero variance indices using caret's  *nearZeroVar* with the default values.
```{r, echo=TRUE}
indexNearZero <- nearZeroVar(dataOriginal)
str(indexNearZero)
data<-dataOriginal[, -indexNearZero]
dim(data)
```

We have reduced the number of columns to `r dim(data)[2]`.

Next we notice that many remaining predictors have large number of NA values
```{r, echo=TRUE}
NAdata<-is.na(data)
NAdataCount<-colSums(NAdata)
```

First We find these predictrors:
```{r, echo=TRUE}
LargeNAdataCount<-NAdataCount[NAdataCount>19000]
LargeNAdataCountNames<-names(LargeNAdataCount)
LargeNAdataCountNames
```

And we exclude these predictors them: 

```{r, echo=TRUE}
data<-data[, -which(names(data) %in% LargeNAdataCountNames)]
```

At this point we have `r dim(data)[2]` predictors left. Finally we perform
a correlation analysis among the remaining predictors using caret's findCorrelation.
In this setting a cut off-threshold of 80% was used.
We exclude column 54 (classe).

```{r, echo=TRUE}
correlated <- findCorrelation(cor(data[, -54]), cutoff = 0.80, verbose=FALSE)
data<-data[, -correlated]
dim(data)
```

We are now ready to perfom model training and selection. The final dataset consists of `r dim(data)[1]` samples
having `r dim(data)[2]-1` numeric predictors. 

```{r}
str(data)
````

## 2.Model selection

In this study we use SVM and Random Forest classifiers since it has been shown
that they produce accurate models with good generalization properties.

1. SVM classifier
We used a radial basis kernel SVM trained with 4-cross validation and automatically generated 10 different
parameters set (*tuneLength=10*). The input data were first preprocessed (center, scaled)  
```{r}
ppModel<-preProcess(data[, -42])
preProcessedData<-predict(ppModel, data[, -42])
#classModel_svm <-train(x=preProcessedData, y=data[, 42], method="svmRadial", trControl = trainControl(method = "cv", number=4, allowParallel = TRUE), tuneLength=10)
```
Tuning parameter 'sigma' was held constant at a value of 0.00879
Accuracy was used to select the optimal model using  the largest value. The final values used for the model were sigma = 0.00879 and C = 128.

```{r}
load('classModel_svm.RData')
plot(classModel_svm)
```

The classification accuracy on the training set was:

```{r}
p<-predict(classModel_svm, preProcessedData)
confusionMatrix(p, data[, 42])
````

2. Random forests
We trained random forest implementation using caret's train method and we tested 10 different parameters.
Input data were not centered or scaled.
```{r}
#classModel_RF <-train(x=data[, -42], y=data[, 42], method="rf", trControl = trainControl(method = "cv", number=4, allowParallel = TRUE),  tuneLength=10)
```

The resulting model accuracy with respect to the parameters is 

```{r}
load('classModel_RF_1.RData')
plot(classModel_RF)
```

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 15. The classification accuracy on the training set was:

```{r}
p<-predict(classModel_RF, data[, -42])
confusionMatrix(p, data[, 42])
```